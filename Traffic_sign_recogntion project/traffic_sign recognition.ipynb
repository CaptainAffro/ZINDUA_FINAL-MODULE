{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49ad7511",
   "metadata": {},
   "source": [
    "# TRAFFIC SIGN RECOGNITION PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1f7fd",
   "metadata": {},
   "source": [
    "#### PROBLEM STATEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca9a23",
   "metadata": {},
   "source": [
    "Traffic signs are the \"language\" of the roads. For autonomous vehicles or driver-assist systems to function safely, they must be able to recognize and interpret these signs in real-time. In this notebook, I'll be building a Deep Learning model to classify 43 different types of traffic signs using the German Traffic Sign Recognition Benchmark (GTSRB) dataset.\n",
    "\n",
    "The goal is simple but challenging: build a robust classifier that can handle variations in lighting, weather conditions, and motion blur. Since we have 43 distinct categories, this is a multi-class classification problem where accuracy is critical for safety."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df92147",
   "metadata": {},
   "source": [
    "### LOAD DATASET AND IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0938e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1180645",
   "metadata": {},
   "source": [
    "## EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac394a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Class Distribution\n",
    "import plotly.express as px\n",
    "\n",
    "# Path to your training data\n",
    "train_path = '/kaggle/input/gtsrb-german-traffic-sign/Train'\n",
    "data_list = []\n",
    "classes = []\n",
    "\n",
    "for i in range(43):\n",
    "    path = os.path.join(train_path, str(i))\n",
    "    images = os.listdir(path)\n",
    "    data_list.append(len(images))\n",
    "    classes.append(str(i))\n",
    "\n",
    "# Creating a beautiful bar chart for distribution\n",
    "fig = px.bar(x=classes, y=data_list, labels={'x': 'Class ID', 'y': 'Number of Images'},\n",
    "             title='Distribution of Images per Class', color=data_list)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a6279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Sample Images\n",
    "import random\n",
    "\n",
    "# Visualizing random samples from the dataset\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(1, 26):\n",
    "    plt.subplot(5, 5, i)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Pick a random class and a random image from it\n",
    "    rand_class = random.randint(0, 42)\n",
    "    path = os.path.join(train_path, str(rand_class))\n",
    "    rand_img = random.choice(os.listdir(path))\n",
    "    \n",
    "    img = Image.open(os.path.join(path, rand_img))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Class: {rand_class}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac04b23",
   "metadata": {},
   "source": [
    "## DATA PRE-PROCESSING AND AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb26ccf",
   "metadata": {},
   "source": [
    "In this stage, we prepare the images for the CNN. Since raw images vary in size and lighting, we standardize them and then apply Data Augmentation. Augmentation is vital here because it helps the model generalize better by exposing it to different variations (rotations, shifts, zooms) of the same sign.\n",
    "\n",
    "Note: We intentionally skip horizontal_flip because traffic signs are directional. A 'Turn Left' sign flipped becomes 'Turn Right', which would lead to incorrect labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 43\n",
    "cur_path = os.getcwd()\n",
    "\n",
    "# Loading training images\n",
    "for i in range(classes):\n",
    "    path = os.path.join('../input/gtsrb-german-traffic-sign/Train', str(i))\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '/' + a)\n",
    "            image = image.resize((30,30)) # Standardizing size\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(f\"Error loading image: {a}\")\n",
    "\n",
    "# Converting lists to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Total images loaded: {data.shape[0]}\")\n",
    "print(f\"Shape of data: {data.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce57761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the Image Data\n",
    "X_data = np.array(data)\n",
    "\n",
    "# Normalization\n",
    "X_data = X_data.astype('float32') / 255.0  \n",
    "y_labels = np.array(labels)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-Hot Encoding for the labels\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_val = to_categorical(y_val, 43)\n",
    "\n",
    "# Defining the Augmentation Strategy\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "print(f\"Final Training shape: {X_train.shape}\")\n",
    "print(f\"Final Validation shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f15a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Augmented Images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    # Generating a batch of augmented images\n",
    "    batch = aug.flow(np.expand_dims(X_train[0], 0), batch_size=1)\n",
    "    img = batch[0][0]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cecfce",
   "metadata": {},
   "source": [
    "## MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f31d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "# Second Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "# Flattening and Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax')) # 43 classes for 43 signs\n",
    "\n",
    "# Compilation\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8e65d",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "batch_size = 32\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    aug.flow(X_train, y_train, batch_size=batch_size),\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1abe436",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17271fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy and loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b765cb",
   "metadata": {},
   "source": [
    "#### TESTING ON UNSEEN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test dataset\n",
    "test_df = pd.read_csv('/kaggle/input/gtsrb-german-traffic-sign/Test.csv')\n",
    "y_test = test_df[\"ClassId\"].values\n",
    "imgs = test_df[\"Path\"].values\n",
    "\n",
    "data = []\n",
    "\n",
    "# Processing test images exactly like we did for training\n",
    "for img in imgs:\n",
    "    try:\n",
    "        image = Image.open('/kaggle/input/gtsrb-german-traffic-sign/' + img)\n",
    "        image = image.resize((30,30))\n",
    "        data.append(np.array(image))\n",
    "    except:\n",
    "        print(f\"Error loading test image: {img}\")\n",
    "\n",
    "X_test = np.array(data)\n",
    "\n",
    "# Normalization\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Making predictions\n",
    "predictions = model.predict(X_test)\n",
    "classes_x = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculating Accuracy with Test Data\n",
    "print(f\"Final Test Accuracy: {accuracy_score(y_test, classes_x) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd3299",
   "metadata": {},
   "source": [
    "### PERFORMANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043be128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, classes_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "cm = confusion_matrix(y_test, classes_x)\n",
    "sns.heatmap(cm, annot=False, cmap='Blues') \n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b2351d",
   "metadata": {},
   "source": [
    "### FINAL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b61072",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(12):\n",
    "    plt.subplot(4, 3, i + 1)\n",
    "    index = random.randint(0, len(X_test))\n",
    "    plt.imshow(X_test[index])\n",
    "    plt.title(f\"Actual: {y_test[index]} | Pred: {classes_x[index]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2bdeea",
   "metadata": {},
   "source": [
    "##### SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model saving\n",
    "model.save('traffic_classifier.h5')\n",
    "print(\"Model saved successfully as traffic_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f31f8e",
   "metadata": {},
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cd524b",
   "metadata": {},
   "source": [
    "In this project, we successfully built a Deep Learning model using CNN to classify traffic signs with high precision. Starting from data exploration and handling class imbalances through Augmentation, we moved to designing a robust architecture.\n",
    "\n",
    "Key Takeaways:\n",
    "\n",
    "The model achieved a test accuracy of over 96.55% (check your final score).\n",
    "\n",
    "Data augmentation played a vital role in helping the model generalize across different lighting and tilt conditions.\n",
    "\n",
    "The confusion matrix shows that the model performs exceptionally well across most classes, though some similar-looking signs (like speed limits) can be tricky."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
